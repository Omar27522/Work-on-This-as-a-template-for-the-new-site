<style>
.gpu {
    font-size: 18px;
    color: rgb(41, 161, 43);
}

.amd {
    font-size: 25px;
    color: rgb(237, 28, 36);
}

.nvidia {
    font-size: 25px;
    color: rgb(118, 185, 0);
}
</style>
</head>
<!-- (-.-)Zzz...--|c[_]|--☁【ツ】☁--|c[_]|--\(^-^)/--|c[_]|--(╯°□°）╯ ︵ ┻━┻ **`ღ´** -->

<div class="container article">
    <a href="?hw/sw#cpu">
        <h2 id="gpu">
            <?= empty($title) ? $titulo[0] : $title[0] ?>
        </h2>
    </a>
    <a href="<?= $links[0] ?>" title="PC magazine">
        <h4 style="text-align:right; padding-right: 250px;">The GPU</h4>
    </a>
    <video controls width="623" height="623" autoplay muted>
        <source src="https://latinospc.com/images/video/wavesgpu.mp4" type="video/mp4">
        Your browser does not support the video tag.
    </video>
    <h4>by Omar Garcia Using ChatGPT on April 13th 2023</h4>
    <p>Computer graphics has come a long way since its inception in the early 1950s. In the early days of computing,
        graphics were primarily used to create simple images and diagrams for scientific and engineering purposes.
        However, with the advent of gaming and multimedia, the demand for more sophisticated and realistic graphics grew
        exponentially.</p>
    <h2>Here are some of the milestones in the history of computer graphics, with a particular focus on the role of
        GPUs:</h2>
    <p>The first digital computer graphics were created in the 1950s using vector graphics systems that used <a
            href="https://en.wikipedia.org/wiki/Cathode-ray_tube" title="cathode ray tubes">cathode ray tubes</a> to
        display simple line drawings.</p>
    <p>In the 1960s, <a href="<?= $links["IvanSutherland"][0] ?>" title="Ivan Sutherland">
            <?= $links["IvanSutherland"][1] ?></a> created Sketchpad, the first
        computer program that could draw images on a computer screen. Sketchpad laid the groundwork for modern computer
        graphics and user interfaces.</p>
    <p>In the 1970s, computer graphics became more sophisticated with the introduction of the first 3D graphics
        software, such as the University of Utah&#39;s &quot;<a href="https://en.wikipedia.org/wiki/Utah_teapot"
            title="University of Utah">Utah Teapot</a>&quot; program.</p>
    <p>The 1980s saw the introduction of the first personal computers with <a
            href="https://www.computerhope.com/jargon/g/gui.htm" title="GUI">graphical user interfaces (GUIs)</a> such
        as the Apple Macintosh and the IBM PC. This helped to popularize computer graphics and bring it into the
        mainstream.</p>
    <p>In the 1990s, the introduction of dedicated <a href="https://www.techspot.com/article/650-history-of-the-gpu/"
            title="GPU">graphics processing units (GPUs)</a> allowed computers to render 3D graphics in real-time,
        enabling the development of 3D video games and other applications.</p>
    <p>The early 2000s saw the introduction of the first <a
            href="https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units"
            title="GPGPU">programmable GPUs</a>, which allowed developers to create custom shaders and other advanced
        visual effects.</p>
    <p>In 2006, <a href="https://developer.nvidia.com/about-cuda" title="CUDA">NVIDIA</a> introduced the <a
            href="https://en.wikipedia.org/wiki/CUDA" title="CUDA wiki">CUDA platform</a>, which allowed developers to
        harness the power of the GPU for general-purpose computing tasks.</p>
    <p>In recent years, advances in GPU technology have enabled the development of cutting-edge graphics techniques such
        as <a href="https://developer.nvidia.com/rtx/ray-tracing" title="Ray Tracing">real-time ray tracing</a> and <a
            href="https://www.run.ai/guides/gpu-deep-learning/best-gpu-for-deep-learning" title="Run AI">machine
            learning-based image processing</a>.</p>
</div><!-- (-.-)Zzz...--|c[_]|--☁【ツ】☁--|c[_]|--\(^-^)/--|c[_]|--(╯°□°）╯ ︵ ┻━┻ **`ღ´** GPU-->


<div class="fullbar article">
    <img alt="GPU Grid" src="https://latinospc.com/images/hardware/hw/gpu-graphics1.jpg" title="GPU graphics" /></p>
    <h2><a href="https://www.intel.com/content/www/us/en/products/docs/processors/what-is-a-gpu.html"
            title="Modern GPU technology powers traditional graphics applications—and much more.">GPU&rsquo;s Where are
            they?</a></h2>
    <p>The use of GPUs for computations has grown rapidly in recent years, with a wide range of applications and
        markets. Here are some of the areas of GPU computations and markets where they are commonly used:</p>
    <p><strong class="gpu">Gaming:</strong> GPUs are used extensively in the gaming industry to render 3D graphics in
        real-time, allowing gamers to experience immersive and realistic gaming environments.</p>
    <p><strong class="gpu">Machine learning and AI:</strong> GPUs have become essential for training deep learning
        models and other forms of artificial intelligence. They are used in a wide range of applications, from image and
        speech recognition to natural language processing.</p>
    <p><strong class="gpu">Scientific computing:</strong> GPUs are increasingly used for scientific simulations, such as
        weather modeling, fluid dynamics, and molecular dynamics. They can perform complex calculations much faster than
        traditional CPU-based systems.</p>
    <p><strong class="gpu">Finance:</strong> GPUs are used in finance for risk management, algorithmic trading, and
        portfolio optimization. They can quickly analyze large datasets and execute complex mathematical models.</p>
    <p><strong class="gpu">Healthcare:</strong> GPUs are used in healthcare for medical imaging and diagnosis, drug
        discovery, and genomics research. They can process large amounts of data quickly and efficiently, helping
        doctors and researchers make more informed decisions.</p>
    <p><strong class="gpu">Cryptocurrency mining:</strong> GPUs are used in cryptocurrency mining to solve complex
        mathematical algorithms and earn rewards. This has led to a significant increase in demand for high-performance
        GPUs in recent years.</p>
    <p><strong class="gpu">Media and entertainment:</strong> GPUs are used in the film and animation industries for
        special effects, rendering, and post-production. They allow for faster rendering times and more realistic
        graphics.</p>
    <p class="spacer_shape"><a href="https://en.wikipedia.org/wiki/GDDR_SDRAM" title="GDDR">GDDR</a> is a type of memory
        that is specially designed for graphics cards. It stands for Graphics Double Data Rate, which means it can
        transfer data twice as fast as regular <a href="?hw_ram#ram" title="RAM">DDR memory</a>. GDDR memory is
        optimized for high bandwidth and low latency, which are important for rendering high-resolution images and
        videos. There are different versions of GDDR memory, such as <a href="https://en.wikipedia.org/wiki/GDDR5_SDRAM"
            title="GDDR5">GDDR5</a>, <a href="https://en.wikipedia.org/wiki/GDDR6_SDRAM" title="GDDR6">GDDR6</a>, <a
            href="https://en.wikipedia.org/wiki/GDDR6_SDRAM#GDDR6X" title="GDDR6X">GDDR6X</a>, and <a
            href="https://en.wikipedia.org/wiki/GDDR7_SDRAM" title="GDDR7">GDDR7</a> each with different specifications
        and performance.</p>
</div><!-- (-.-)Zzz...--|c[_]|--☁【ツ】☁--|c[_]|--\(^-^)/--|c[_]|--(╯°□°）╯ ︵ ┻━┻ **`ღ´** GPU-->

<div class="fullbar article">
    <h2 class="tnhkl">GPU Manufacturers:</h2>
    <p>There are several major players in the GPU industry, each with their own strengths and market focus. Here are
        some of the most prominent companies in the GPU industry:</p>
    <h2><a href="https://www.nvidia.com/en-us/geforce/graphics-cards/" title="NVIDIA" class="tnhkl">NVIDIA:</a></h2>
    <p>The leading player in the GPU industry, with a focus on gaming, data center, and AI applications. The
        company&#39;s GeForce and Quadro product lines are popular with gamers and professionals, while its Tesla line
        of GPUs is designed for data center and scientific computing applications.</p>
    <h2><a href="https://www.amd.com/en/graphics/workstations" title="" class="tnhkl">AMD:</a></h2>
    <p>AMD is another major player in the GPU industry, with a focus on gaming and data center applications. The
        company&#39;s Radeon product line is popular with gamers and professionals, while its Instinct line of GPUs is
        designed for data center and scientific computing applications.</p>
    <h2><a href="https://www.intel.com/content/www/us/en/products/details/discrete-gpus/arc.html" title="Arc"
            class="tnhkl">Intel:</a></h2>
    <p>Intel is a dominant player in the CPU market, but it has recently entered the GPU market with its Xe product
        line. The company is targeting the gaming, data center, and AI markets with its GPUs.</p>
    <h2><a href="https://www.qualcomm.com/products/features/adreno" title="Adreno" class="tnhkl">Qualcomm:</a></h2>
    <p>Qualcomm is a major player in the mobile GPU market, with its Adreno product line used in many smartphones and
        tablets.</p>
    <h2><a href="https://www.imaginationtech.com/products/gpu/" title="Imagination" class="tnhkl">Imagination
            Technologies:</a></h2>
    <p>Imagination Technologies is a UK-based company that designs and licenses GPUs for use in mobile and embedded
        devices. Its PowerVR product line is used in many smartphones and other mobile devices.</p>
    <h2><a href="https://www.arm.com/products/silicon-ip-multimedia" title="Arm" class="tnhkl">ARM:</a></h2>
    <p>ARM is a UK-based company that designs CPUs and GPUs for use in mobile and embedded devices. Its Mali product
        line is used in many smartphones and other mobile devices.</p>
</div><!-- (-.-)Zzz...--|c[_]|--☁【ツ】☁--|c[_]|--\(^-^)/--|c[_]|--(╯°□°）╯ ︵ ┻━┻ **`ღ´** GPU-->

<div class="fullbar article">
    <h2>Here is a simplified List of GPU series from AMD Radeon, Nvidia, and Intel:</h2>
    <div class="spacer"></div>
    <div style="text-align: center"><a href="https://en.wikipedia.org/wiki/List_of_AMD_graphics_processing_units"
            title="List of GPUs">
            <h2 class="amd">AMD</h2>
        </a></div>
    <div class="spacer_shape">
        <p><a href="https://en.wikipedia.org/wiki/Radeon_HD_7000_series" title="Radeon HD 7000" class="amd">HD 7000:</a>
            Launched in 2012, based on the <a href="https://en.wikipedia.org/wiki/Graphics_Core_Next"
                title="GCN">GCN</a>" 1.0 architecture, supports <a
                href="https://en.wikipedia.org/wiki/DirectX#DirectX_11" title="DirectX 11.1">DirectX 11.1</a> and <a
                href="https://en.wikipedia.org/wiki/OpenGL" title="OpenGL">OpenGL</a>" 4.3</p>
        <p><a href="https://en.wikipedia.org/wiki/Radeon_200_series" title="RX 200" class="amd">RX 200:</a> Launched in
            2013, based on the <a href="https://en.wikipedia.org/wiki/Graphics_Core_Next" title="GCN">GCN</a>" 1.1 and
            1.2 architectures, supports <a href="https://en.wikipedia.org/wiki/DirectX#DirectX_12"
                title="DirectX 12">DirectX 12</a>" and <a href="https://en.wikipedia.org/wiki/OpenGL"
                title="OpenGL">OpenGL</a>" 4.4¹</p>
        <p><a href="https://en.wikipedia.org/wiki/Radeon_300_series" title="RX 300" class="amd">RX 300:</a> Launched in
            2015, based on the <a href="https://en.wikipedia.org/wiki/Graphics_Core_Next" title="GCN">GCN</a>" 1.2
            architecture, supports <a href="https://en.wikipedia.org/wiki/DirectX#DirectX_12" title="DirectX 12">DirectX
                12</a>" and <a href="https://en.wikipedia.org/wiki/OpenGL" title="OpenGL">OpenGL</a>" 4.5.</p>
        <p><a href="https://en.wikipedia.org/wiki/Radeon_400_series" title="RX 400" class="amd">RX 400:</a> Launched in
            2016, based on the <a href="https://en.wikipedia.org/wiki/Graphics_Core_Next" title="GCN">GCN</a>" 4.0
            architecture, supports <a href="https://en.wikipedia.org/wiki/DirectX#DirectX_12" title="DirectX 12">DirectX
                12</a>" and <a href="https://en.wikipedia.org/wiki/Vulkan" title="Vulkan">Vulkan</a>"</p>
        <p><a href="https://en.wikipedia.org/wiki/Radeon_500_series" title="RX 500" class="amd">RX 500:</a> Launched in
            2017, based on the <a href="https://en.wikipedia.org/wiki/Graphics_Core_Next" title="GCN">GCN</a>" 4.0
            architecture, supports <a href="https://en.wikipedia.org/wiki/DirectX#DirectX_12" title="DirectX 12">DirectX
                12</a>" and <a href="https://en.wikipedia.org/wiki/Vulkan" title="Vulkan">Vulkan</a>"</p>
        <p><a href="https://en.wikipedia.org/wiki/Radeon_RX_Vega_series" title="RX Vega" class="amd">RX Vega:</a>
            Launched in 2017, based on the <a href="https://en.wikipedia.org/wiki/Graphics_Core_Next"
                title="GCN">GCN</a>" 5.0 architecture, supports <a
                href="https://en.wikipedia.org/wiki/DirectX#DirectX_12" title="DirectX 12">DirectX 12</a>" and <a
                href="https://en.wikipedia.org/wiki/Vulkan" title="Vulkan">Vulkan</a>", uses <a
                href="https://en.wikipedia.org/wiki/High_Bandwidth_Memory" title="High Bandwidth Memory">HBM2</a>"</p>
        <p><a href="https://en.wikipedia.org/wiki/Radeon_RX_5000_series" title="RX 5000" class="amd">RX 5000:</a>
            Launched in 2019, based on the <a href="https://en.wikipedia.org/wiki/RDNA_(microarchitecture)"
                title="RDNA">RDNA</a>" architecture, supports <a href="https://en.wikipedia.org/wiki/DirectX#DirectX_12"
                title="DirectX 12">DirectX 12</a>" and <a href="https://en.wikipedia.org/wiki/Vulkan"
                title="Vulkan">Vulkan</a>", uses GDDR6</p>
        <p><a href="https://en.wikipedia.org/wiki/Radeon_RX_6000_series" title="RX 6000" class="amd">RX 6000:</a>
            Launched in 2020, based on the <a href="https://en.wikipedia.org/wiki/RDNA_(microarchitecture)"
                title="RDNA">RDNA</a>" 2 architecture, supports <a
                href="https://en.wikipedia.org/wiki/DirectX#DirectX_12" title="DirectX 12">DirectX 12</a>" Ultimate and
            <a href="https://en.wikipedia.org/wiki/Vulkan" title="Vulkan">Vulkan</a>", uses GDDR6 and Infinity Cache
        </p>
        <p><a href="https://en.wikipedia.org/wiki/Radeon_RX_7000_series" title="RX 7000" class="amd">RX 7000:</a>
            Launched in 2023, based on the <a href="https://en.wikipedia.org/wiki/RDNA_(microarchitecture)"
                title="RDNA">RDNA</a>" 3 architecture, supports <a
                href="https://en.wikipedia.org/wiki/DirectX#DirectX_12" title="DirectX 12">DirectX 12</a>" Ultimate and
            <a href="https://en.wikipedia.org/wiki/Vulkan" title="Vulkan">Vulkan</a>", uses GDDR6X and Infinity Cache
        </p>
        <p><a href="https://en.wikipedia.org/wiki/Radeon_Pro#Radeon_Pro_Duo" title="Radeon Pro" class="amd">Radeon
                Pro:</a>For workstation with needed high-performance and reliable graphics for various applications,
            such as computer-aided design (CAD), computer-generated imagery (CGI), digital content creation (DCC),
            high-performance computing (HPC), and virtual reality (VR).</p>
    </div>
    <div class="spacer"></div>
    <div style="text-align: center"><a href="https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units"
            title="list of GPUs">
            <h2 class="nvidia">Nvidia</h2>
        </a></div>
    <p><b class="nvidia">GT:</b> For casual gamers and general users who need a basic graphics card for everyday tasks
        such as web browsing, video streaming, photo editing, and light gaming. GT cards are the cheapest and
        lowest-performing ones in the GeForce lineup.</p>
    <p><b class="nvidia">GTS:</b> For budget-conscious gamers who want a decent graphics card for playing older or less
        demanding games at medium to high settings. GTS cards are slightly better than GT cards in terms of performance
        and features, but they are also more expensive and consume more power.</p>
    <p><b class="nvidia">GTX:</b> For enthusiasts and hardcore gamers who want a high-end graphics card for playing the
        latest and most demanding games at high to ultra settings. GTX cards are the flagship models of each generation,
        offering superior processor performance, more shader pipelines, more and faster memory, and bigger heatsinks
        than GTS cards.</p>
    <p><b class="nvidia">GTX+</b> Cards also have a "+" variant, which means a slightly improved version of the original
        model with higher clock speeds and memory bandwidth.</p>
    <p><b class="nvidia">RTX:</b> For gamers and creators who want a cutting-edge graphics card that supports ray
        tracing and AI acceleration. RTX cards are the newest and most advanced models of the GeForce lineup, adding ray
        tracing cores and tensor cores to the GTX architecture . Ray tracing cores enable realistic lighting, shadows,
        and reflections in games, while tensor cores enable AI-based features such as DLSS (Deep Learning Super
        Sampling), which boosts performance and image quality.</p>
    <div class="spacer_shape">
        <p><a href="https://en.wikipedia.org/wiki/GeForce_8_series" title="GeForce 8 series" class="nvidia">GeForce
                8000:</a> Launched in 2006, based on the <a href="https://en.wikipedia.org/wiki/Nvidia_Tesla"
                title="Tesla architecture">Tesla architecture</a>, supports <a
                href="https://en.wikipedia.org/wiki/DirectX#DirectX_10" title="DirectX 10">DirectX 10</a> and <a
                href="https://en.wikipedia.org/wiki/OpenGL" title="OpenGL">OpenGL</a>" 3.3</p>
        <p><a href="https://en.wikipedia.org/wiki/GeForce" title="GeForce" class="nvidia">GeForce
                GTX/RTX/GT/GTS/GTX+:</a> Launched between 2008 and 2020, based on various architectures such as <a
                href="https://en.wikipedia.org/wiki/Fermi_(microarchitecture)" title="Fermi Architecture">Fermi</a>,
            <a href="https://en.wikipedia.org/wiki/Kepler_(microarchitecture)" title="Kepler Architecture">Kepler</a>,
            <a href="https://en.wikipedia.org/wiki/Maxwell_(microarchitecture)"
                title="Maxwell Architecture">Maxwell</a>,
            <a href="https://en.wikipedia.org/wiki/Pascal_(microarchitecture)" title="Pascal Architecture">Pascal</a>,
            <a href="https://en.wikipedia.org/wiki/Turing_(microarchitecture)" title="Turing Architecture">Turing</a>,
            and <a href="https://en.wikipedia.org/wiki/Ampere_(microarchitecture)"
                title="Ampere Architecture">Ampere</a>, supports various versions of <a
                href="https://en.wikipedia.org/wiki/DirectX" title="DirectX">DirectX</a>,
            <a href="https://en.wikipedia.org/wiki/OpenGL" title="OpenGL">OpenGL</a>, and <a
                href="https://en.wikipedia.org/wiki/Vulkan" title="Vulkan">Vulkan</a>"
        </p>
        <p><a href="https://en.wikipedia.org/wiki/GeForce#GeForce_40_series_(Current)" title="Current Cards"
                class="nvidia">GeForce RTX/GTX/GT/GTS/GTX+:</a> Launched between 2020 and 2023, based on the <a
                href="https://en.wikipedia.org/wiki/Ada_Lovelace_(microarchitecture)"
                title="Ada Lovelace architecture">Ada Lovelace architecture</a>, supports <a
                href="https://en.wikipedia.org/wiki/DirectX#DirectX_12_Ultimate" title="DirectX 12 Ultimate">DirectX 12
                Ultimate</a> and <a href="https://en.wikipedia.org/wiki/Vulkan" title="Vulkan">Vulkan</a>", uses GDDR6X
            and <a
                href="https://nvidianews.nvidia.com/news/nvidia-introduces-dlss-3-with-breakthrough-ai-powered-frame-generation-for-up-to-4x-performance"
                title="DLSS 3">DLSS 3 Frame Generation</a></p>
    </div>
    <h2><a href="https://www.intel.com/content/www/us/en/products/details/discrete-gpus.html"
            title="Intel Discrete GPUs">
            <div style="text-align: center">Intel</div>
        </a></h2>
    <p>Intel <a
            href="https://www.intel.com/content/www/us/en/products/docs/discrete-gpus/arc/desktop/a-series/overview.html">A-Series</a>
        Arc has different series of GPUs, each with different performance levels and features. The first series, called
        Alchemist, launched in 2022, followed by Battlemage, Celestial, and Druid in the later years.</p>
    <p>
        The <a href="https://en.wikipedia.org/wiki/Intel_Arc" title="Arc Alchemist">A-Series</a> has two types of chips:
        ACM-G10 and ACM-G11 and both use the <a
            href="https://www.intel.com/content/www/us/en/products/docs/discrete-gpus/arc/technology/xe-hpg-microarchitecture.html"
            title="Xe-HPG">Xe-HPG Microarchitecture</a>, which delivers breakthrough performance, efficiency, and
        scalability for gamers and creators. The ACM-G10 chip has up to 512 Xe Vector Engines (XVEs), which are the
        basic units of computation for graphics and other workloads. The ACM-G11 chip has up to 128 XVEs. Each XVE can
        perform 16 floating-point operations per clock cycle, and each chip also has XMX units that can perform matrix
        operations for deep learning and other tasks.</p>
    <p>The <a href="https://en.wikipedia.org/wiki/Intel_Arc" title="Arc Alchemist">A-Series</a> also supports ray
        tracing, which is a technique for rendering realistic lighting effects in 3D scenes. Each chip has ray tracing
        units (RTUs) that can accelerate the ray tracing calculations. The ACM-G10 chip has 32 RTUs, while the ACM-G11
        chip has 8 RTUs.
    </p>
    <p>
        The <a href="https://en.wikipedia.org/wiki/Intel_Arc" title="Arc Alchemist">A-Series</a> has different models
        for laptops and desktops, with different power and performance levels. The cards are <a
            href="https://www.intel.com/content/www/us/en/products/docs/discrete-gpus/arc/desktop/a-series/3.html"
            title="Arch 3">Arc 3</a>, <a>Arc 5</a>, and <a
            href="https://www.intel.com/content/www/us/en/products/docs/discrete-gpus/arc/desktop/a-series/7.html"
            title="Arc7">Arc 7</a>. The laptop models use the PCIe 4.0 x8 interface, while the desktop models will use
        the PCIe 4.0 x16 interface.
    </p>
    <p>
        The <a href="https://en.wikipedia.org/wiki/Intel_Arc" title="Arc Alchemist">A-Series</a> has various memory
        configurations, depending on the model. The laptop models use GDDR6 memory with a maximum of 16 GB capacity and
        a maximum of 256-bit bus width. The desktop models use GDDR6 or GDDR6X memory with a maximum of 32 GB capacity
        and a maximum of 384-bit bus width².
    </p>
    <p>
        The <a href="https://en.wikipedia.org/wiki/Intel_Arc" title="Arc Alchemist">A-Series</a> has other features,
        such as DLSS (Deep Learning Super Sampling), which is a technique for improving the image quality and
        performance of games by using artificial intelligence. The <a href="https://en.wikipedia.org/wiki/Intel_Arc"
            title="Arc Alchemist">A-Series</a> also supports <a
            href="https://en.wikipedia.org/wiki/DirectX#DirectX_12_Ultimate" title="DirectX 12 Ultimate">DirectX 12
            Ultimate</a>" , <a href="https://en.wikipedia.org/wiki/Vulkan" title="Vulkan">Vulkan</a>", and other
        graphics APIs.</p>
</div>